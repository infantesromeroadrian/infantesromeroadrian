<!-- GitHub Profile Â· AdriÃ¡n Infantes Â· Story/Impact Edition -->

<p align="center">
  <img src="https://github.com/infantesromeroadrian/infantesromeroadrian/blob/3235161b92ac0d7308601ec3ed64ba84a2fb8b52/PHOTO-2024-02-10-01-25-43.jpg" alt="AdriÃ¡n Infantes" width="220" />
</p>

<h1 align="center">AdriÃ¡n Infantes â€” AI Engineer â†’ AI Solutions Architect</h1>
<p align="center">
  <strong>LLMs Â· RAG Â· Agentic Systems Â· AI Security Â· GPU Serving</strong><br/>
  <a href="mailto:infantesromeroadrian@gmail.com">Email</a> Â· 
  <a href="https://www.linkedin.com/in/adrianinfantes">LinkedIn</a> Â· 
  <a href="https://github.com/infantesromeroadrian">GitHub</a>
</p>

---

## ğŸ¯ Resumen
DiseÃ±o, despliegue y defensa de sistemas de IA end-to-end: desde el dataset y el fine-tuning hasta el serving en GPU y la seguridad aplicada a LLMs (guardrails, red teaming, auditorÃ­a). Objetivo a corto plazo: **AI Solutions Architect** con criterios de producciÃ³n y mÃ©tricas pÃºblicas.

---

## ğŸ’¼ Experiencia (quÃ© usÃ©, para quÃ© lo usÃ© y quÃ© conseguÃ­)

### BBVA â€” AI/ML Engineer (Mid/Sr.) Â· 2024 â†’ Presente
**Contexto**: plataformas de LLM para banca, RAG con fuentes internas, cumplimiento y observabilidad enterprise.

- **TecnologÃ­as**
  - **Modelos/TokenizaciÃ³n**: GPT/LLaMA/Mistral, tiktoken, re-rankers.
  - **RAG/Agentes**: LangChain, LangGraph, DSPy; Pinecone/Milvus/FAISS.
  - **Serving/Infra**: vLLM, Triton, TensorRT, CUDA; Docker, Kubernetes, HPA.
  - **MLOps/Observabilidad**: MLflow, Prometheus/Grafana, OpenTelemetry, evals automÃ¡ticas.
  - **Seguridad**: guardrails, policy enforcement, aislamiento de contexto, rate limiting, auditorÃ­a.

- **Para quÃ© lo usÃ©**
  - Construir **RAG verificable** con re-ranking y grounding para documentaciÃ³n y datos financieros.
  - Orquestar **agentes con herramientas** de backoffice manteniendo latencia p95 estable.
  - Desplegar **serving GPU multi-tenant** con autoscaling y control de costes.
  - Implantar **observabilidad**: precisiÃ³n, cobertura, latencia y calidad de citaciones.
  - Endurecer la plataforma LLM frente a inyecciÃ³n de prompts y exfiltraciÃ³n de contexto.

- **QuÃ© conseguÃ­ (mÃ©tricas)**
  - **+15%** precisiÃ³n en anÃ¡lisis financiero con LLMs.
  - **âˆ’20%** tiempos de procesamiento en pipelines crÃ­ticos.
  - **99.9%** uptime en serving y **p95 < 300 ms** en consultas comunes.
  - **âˆ’40%** time-to-market de nuevos flujos (pipeline estandarizado + CI/CD).
  - **+22%** AUC-ROC en detecciÃ³n de fraude con features textuales/semÃ¡nticas.

> `TODO: imagen` diagrama simple de arquitectura (RAG + agente + vLLM + observabilidad).  
> `TODO: enlace` a repos pÃºblicos/redactados o one-pagers tÃ©cnicos.

---

### Capgemini â€” Data Scientist (Jr.) Â· ~4 aÃ±os
**Contexto**: proyectos de analÃ­tica y ML en clientes enterprise; NLP inicial y tabular clÃ¡sico.

- **TecnologÃ­as**
  - **ML clÃ¡sico**: scikit-learn, XGBoost, pipelines de validaciÃ³n, MLflow.
  - **Datos**: SQL, PySpark, orquestaciÃ³n ETL, data lakes.
  - **NLP**: spaCy/NLTK, primeros embeddings y clasificaciÃ³n de intenciÃ³n.
  - **VisualizaciÃ³n/BI**: Dash/Plotly, Power BI; reporting parametrizado.

- **Para quÃ© lo usÃ©**
  - Construir **ETL multi-fuente** con validaciÃ³n y control de calidad.
  - Entrenar **modelos de scoring** y forecasting con trazabilidad/versionado.
  - Desarrollar **NLP de intenciÃ³n** para routing y autoservicio bÃ¡sico.

- **QuÃ© conseguÃ­ (mÃ©tricas)**
  - **+20%** precisiÃ³n en forecast de demanda frente a baseline.
  - **âˆ’30%** ciclo de anÃ¡lisis mensual con dashboards automatizados.
  - **âˆ’35%** tiempos en consultas SQL crÃ­ticas tras optimizaciÃ³n/particionado.

<!-- Imagen solicitada por el autor -->
<p align="center">
  <img src="Generated%20Image%20September%2024,%202025%20-%2010_14PM.png" alt="Capgemini â€” Visual resumen" width="820"/>
</p>

---

### Proyectos personales y consultorÃ­a (selectos)
- **Enterprise RAG (OSS/PoC)**: LLaMA 2/3 + Pinecone + FastAPI + re-rankers.  
  Resultado: **98%** cobertura QA en dominio, grounding y citaciones trazables.  
- **Medical LLM Fine-tuning**: BioMedNLP + LoRA + evals.  
  Resultado: **+40%** en set de validaciÃ³n clÃ­nica especÃ­fico.  
- **Multi-tenant GPU Serving**: Kubernetes + vLLM + autoscaling.  
  Resultado: **5Ã—** reducciÃ³n de coste por request y estabilidad p95 bajo carga.

> Repos con historia:  
> - `TODO` RAG-Ops  
> - `TODO` Agents-Secure  
> - `TODO` vLLM-Serving

---

## ğŸ§  Especialidades tÃ©cnicas
- **LLMs**: fine-tuning/QLoRA, prompts robustos (DSPy), agentes con herramientas.  
- **RAG**: re-ranking, fusiÃ³n de resultados, verificaciÃ³n y citaciÃ³n.  
- **Serving en GPU**: vLLM, Triton, TensorRT, cuantizaciÃ³n (GGUF/AWQ), batching/throughput.  
- **MLOps**: MLflow, regresiÃ³n de calidad, evals automÃ¡ticas, trazabilidad end-to-end.  
- **AI Security**: threat modeling LLM, guardrails, aislamiento de contexto, auditorÃ­a y polÃ­ticas.  
- **Datos**: SQL, PySpark, validaciÃ³n y linaje; vector DBs (Pinecone, Milvus, FAISS).

---

## ğŸ§­ FormaciÃ³n y ruta acadÃ©mica
- **Doble Grado (en curso)** â€” Ciberseguridad & Hacking + IngenierÃ­a en MecatrÃ³nica (MSMK, 2025 â†’)  
  Ãšltimo aÃ±o vÃ­a acuerdo Pearson en el extranjero (p. ej., titulaciÃ³n por Napier University, Edimburgo).
- **MÃ¡steres y especializaciones (completados)**  
  - Big Data & Data Science  
  - Deep Learning & Generative AI  
  - Bootcamps avanzados en NLP/LLMs, LangChain/LangGraph, MLOps
- **Certificaciones**  
  - Microsoft **AI-900** Â· **AI-102**  
  - NVIDIA **Accelerated**  
  - TMC Security **OSINT**

> `TODO: imÃ¡genes` diplomas/insignias 600â€“800 px.

---

## ğŸ“Š Observabilidad y mÃ©tricas (lo que monitorizo)
- Calidad: precisiÃ³n, cobertura, groundedness/citations, robustez a prompts adversarios.  
- Rendimiento: latencia p50/p95/p99, tokens/s, throughput por GPU, colas.  
- Coste: coste por 1k tokens, por request y por tenant.  
- Fiabilidad: uptime, errores por categorÃ­a, SLOs/SLA y alertas.

---

## ğŸ”§ Toolkit
**Modelos/Frameworks**: PyTorch, TensorFlow, vLLM, Triton, TensorRT, DSPy  
**RAG/Agentes**: LangChain, LangGraph, Pinecone, Milvus, FAISS, re-rankers  
**Infra**: Docker, Kubernetes, CUDA, autoscaling, CI/CD  
**Data/MLOps**: SQL, PySpark, MLflow, OpenTelemetry, Prometheus/Grafana  
**Seguridad IA**: guardrails, policy enforcement, rate limiting, auditorÃ­a

<p>
  <img src="https://img.shields.io/badge/PyTorch-%23EE4C2C?logo=pytorch&logoColor=white&style=for-the-badge"/>
  <img src="https://img.shields.io/badge/CUDA-%2376B900?logo=nvidia&logoColor=white&style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Kubernetes-%23326CE5?logo=kubernetes&logoColor=white&style=for-the-badge"/>
  <img src="https://img.shields.io/badge/vLLM-%23000000?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/LangChain-%23000000?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/MLflow-%23019B8F?style=for-the-badge"/>
</p>

---

## ğŸ—ºï¸ Roadmap inmediato
- Shift-left security en pipelines de IA.  
- Zero-downtime para agentes multi-tenant en K8s con autoscaling inteligente.  
- IntegraciÃ³n mecatrÃ³nica: percepciÃ³n-decisiÃ³n-acciÃ³n con validaciÃ³n programÃ¡tica.

---

## ğŸ“ˆ Stats (opcionales)
<details>
<summary>Mostrar</summary>

![GitHub Stats](https://github-readme-stats.vercel.app/api?username=infantesromeroadrian&theme=dark&show_icons=true&hide_border=true)
![Top Languages](https://github-readme-stats.vercel.app/api/top-langs/?username=infantesromeroadrian&layout=compact&theme=dark)
![Trophies](https://github-profile-trophy.vercel.app/?username=infantesromeroadrian&theme=onedark&no-frame=true&margin-w=15)

</details>

---

## ğŸ¤ ColaboraciÃ³n
Arquitectura LLM, RAG y agentes con criterios de producciÃ³n; hardening y red teaming de IA; PoCs con mÃ©tricas pÃºblicas.  
<a href="mailto:infantesromeroadrian@gmail.com">infantesromeroadrian@gmail.com</a> Â· <a href="https://www.linkedin.com/in/adrianinfantes">LinkedIn</a>


