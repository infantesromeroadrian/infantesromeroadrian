<!-- GitHub Profile · Adrián Infantes · Story/Impact Edition -->

<p align="center">
  <img src="https://github.com/infantesromeroadrian/infantesromeroadrian/blob/3235161b92ac0d7308601ec3ed64ba84a2fb8b52/PHOTO-2024-02-10-01-25-43.jpg" alt="Adrián Infantes" width="220" />
</p>

<h1 align="center">Adrián Infantes — AI Engineer → AI Solutions Architect</h1>
<p align="center">
  <strong>LLMs · RAG · Agentic Systems · AI Security · GPU Serving</strong><br/>
  <a href="mailto:infantesromeroadrian@gmail.com">Email</a> · 
  <a href="https://www.linkedin.com/in/adrianinfantes">LinkedIn</a> · 
  <a href="https://github.com/infantesromeroadrian">GitHub</a>
</p>

---

## 🎯 Resumen
Diseño, despliegue y defensa de sistemas de IA end-to-end: desde el dataset y el fine-tuning hasta el serving en GPU y la seguridad aplicada a LLMs (guardrails, red teaming, auditoría). Objetivo a corto plazo: **AI Solutions Architect** con criterios de producción y métricas públicas.

---

## 💼 Experiencia (qué usé, para qué lo usé y qué conseguí)

### BBVA — AI/ML Engineer (Mid/Sr.) · 2024 → Presente
**Contexto**: plataformas de LLM para banca, RAG con fuentes internas, cumplimiento y observabilidad enterprise.

- **Tecnologías**
  - **Modelos/Tokenización**: GPT/LLaMA/Mistral, tiktoken, re-rankers.
  - **RAG/Agentes**: LangChain, LangGraph, DSPy; Pinecone/Milvus/FAISS.
  - **Serving/Infra**: vLLM, Triton, TensorRT, CUDA; Docker, Kubernetes, HPA.
  - **MLOps/Observabilidad**: MLflow, Prometheus/Grafana, OpenTelemetry, evals automáticas.
  - **Seguridad**: guardrails, policy enforcement, aislamiento de contexto, rate limiting, auditoría.

- **Para qué lo usé**
  - Construir **RAG verificable** con re-ranking y grounding para documentación y datos financieros.
  - Orquestar **agentes con herramientas** de backoffice manteniendo latencia p95 estable.
  - Desplegar **serving GPU multi-tenant** con autoscaling y control de costes.
  - Implantar **observabilidad**: precisión, cobertura, latencia y calidad de citaciones.
  - Endurecer la plataforma LLM frente a inyección de prompts y exfiltración de contexto.

- **Qué conseguí (métricas)**
  - **+15%** precisión en análisis financiero con LLMs.
  - **−20%** tiempos de procesamiento en pipelines críticos.
  - **99.9%** uptime en serving y **p95 < 300 ms** en consultas comunes.
  - **−40%** time-to-market de nuevos flujos (pipeline estandarizado + CI/CD).
  - **+22%** AUC-ROC en detección de fraude con features textuales/semánticas.

> `TODO: imagen` diagrama simple de arquitectura (RAG + agente + vLLM + observabilidad).  
> `TODO: enlace` a repos públicos/redactados o one-pagers técnicos.

---

### Capgemini — Data Scientist (Jr.) · ~4 años
**Contexto**: proyectos de analítica y ML en clientes enterprise; NLP inicial y tabular clásico.

- **Tecnologías**
  - **ML clásico**: scikit-learn, XGBoost, pipelines de validación, MLflow.
  - **Datos**: SQL, PySpark, orquestación ETL, data lakes.
  - **NLP**: spaCy/NLTK, primeros embeddings y clasificación de intención.
  - **Visualización/BI**: Dash/Plotly, Power BI; reporting parametrizado.

- **Para qué lo usé**
  - Construir **ETL multi-fuente** con validación y control de calidad.
  - Entrenar **modelos de scoring** y forecasting con trazabilidad/versionado.
  - Desarrollar **NLP de intención** para routing y autoservicio básico.

- **Qué conseguí (métricas)**
  - **+20%** precisión en forecast de demanda frente a baseline.
  - **−30%** ciclo de análisis mensual con dashboards automatizados.
  - **−35%** tiempos en consultas SQL críticas tras optimización/particionado.

<!-- Imagen solicitada por el autor -->
<p align="center">
  <img src="Generated%20Image%20September%2024,%202025%20-%2010_14PM.png" alt="Capgemini — Visual resumen" width="820"/>
</p>

---

### Proyectos personales y consultoría (selectos)
- **Enterprise RAG (OSS/PoC)**: LLaMA 2/3 + Pinecone + FastAPI + re-rankers.  
  Resultado: **98%** cobertura QA en dominio, grounding y citaciones trazables.  
- **Medical LLM Fine-tuning**: BioMedNLP + LoRA + evals.  
  Resultado: **+40%** en set de validación clínica específico.  
- **Multi-tenant GPU Serving**: Kubernetes + vLLM + autoscaling.  
  Resultado: **5×** reducción de coste por request y estabilidad p95 bajo carga.

> Repos con historia:  
> - `TODO` RAG-Ops  
> - `TODO` Agents-Secure  
> - `TODO` vLLM-Serving

---

## 🧠 Especialidades técnicas
- **LLMs**: fine-tuning/QLoRA, prompts robustos (DSPy), agentes con herramientas.  
- **RAG**: re-ranking, fusión de resultados, verificación y citación.  
- **Serving en GPU**: vLLM, Triton, TensorRT, cuantización (GGUF/AWQ), batching/throughput.  
- **MLOps**: MLflow, regresión de calidad, evals automáticas, trazabilidad end-to-end.  
- **AI Security**: threat modeling LLM, guardrails, aislamiento de contexto, auditoría y políticas.  
- **Datos**: SQL, PySpark, validación y linaje; vector DBs (Pinecone, Milvus, FAISS).

---

## 🧭 Formación y ruta académica
- **Doble Grado (en curso)** — Ciberseguridad & Hacking + Ingeniería en Mecatrónica (MSMK, 2025 →)  
  Último año vía acuerdo Pearson en el extranjero (p. ej., titulación por Napier University, Edimburgo).
- **Másteres y especializaciones (completados)**  
  - Big Data & Data Science  
  - Deep Learning & Generative AI  
  - Bootcamps avanzados en NLP/LLMs, LangChain/LangGraph, MLOps
- **Certificaciones**  
  - Microsoft **AI-900** · **AI-102**  
  - NVIDIA **Accelerated**  
  - TMC Security **OSINT**

> `TODO: imágenes` diplomas/insignias 600–800 px.

---

## 📊 Observabilidad y métricas (lo que monitorizo)
- Calidad: precisión, cobertura, groundedness/citations, robustez a prompts adversarios.  
- Rendimiento: latencia p50/p95/p99, tokens/s, throughput por GPU, colas.  
- Coste: coste por 1k tokens, por request y por tenant.  
- Fiabilidad: uptime, errores por categoría, SLOs/SLA y alertas.

---

## 🔧 Toolkit
**Modelos/Frameworks**: PyTorch, TensorFlow, vLLM, Triton, TensorRT, DSPy  
**RAG/Agentes**: LangChain, LangGraph, Pinecone, Milvus, FAISS, re-rankers  
**Infra**: Docker, Kubernetes, CUDA, autoscaling, CI/CD  
**Data/MLOps**: SQL, PySpark, MLflow, OpenTelemetry, Prometheus/Grafana  
**Seguridad IA**: guardrails, policy enforcement, rate limiting, auditoría

<p>
  <img src="https://img.shields.io/badge/PyTorch-%23EE4C2C?logo=pytorch&logoColor=white&style=for-the-badge"/>
  <img src="https://img.shields.io/badge/CUDA-%2376B900?logo=nvidia&logoColor=white&style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Kubernetes-%23326CE5?logo=kubernetes&logoColor=white&style=for-the-badge"/>
  <img src="https://img.shields.io/badge/vLLM-%23000000?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/LangChain-%23000000?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/MLflow-%23019B8F?style=for-the-badge"/>
</p>

---

## 🗺️ Roadmap inmediato
- Shift-left security en pipelines de IA.  
- Zero-downtime para agentes multi-tenant en K8s con autoscaling inteligente.  
- Integración mecatrónica: percepción-decisión-acción con validación programática.

---

## 📈 Stats (opcionales)
<details>
<summary>Mostrar</summary>

![GitHub Stats](https://github-readme-stats.vercel.app/api?username=infantesromeroadrian&theme=dark&show_icons=true&hide_border=true)
![Top Languages](https://github-readme-stats.vercel.app/api/top-langs/?username=infantesromeroadrian&layout=compact&theme=dark)
![Trophies](https://github-profile-trophy.vercel.app/?username=infantesromeroadrian&theme=onedark&no-frame=true&margin-w=15)

</details>

---

## 🤝 Colaboración
Arquitectura LLM, RAG y agentes con criterios de producción; hardening y red teaming de IA; PoCs con métricas públicas.  
<a href="mailto:infantesromeroadrian@gmail.com">infantesromeroadrian@gmail.com</a> · <a href="https://www.linkedin.com/in/adrianinfantes">LinkedIn</a>


